#Team Super Awesome Mega Cool
#Demo 1
#Detecting Aruco Marker and angle

# import the necessary packages
import cv2
import board
import adafruit_character_lcd.character_lcd_rgb_i2c as character_lcd
import smbus
import time
# for RPI version 1, use “bus = smbus.SMBus(0)”
bus = smbus.SMBus(1)

# This is the address we setup in the Arduino Program
address = 0x04

# Modify this if you have a different sized Character LCD
lcd_columns = 16
lcd_rows = 2

# Initialise I2C bus.
i2c = board.I2C()  # uses board.SCL and board.SDA

# Initialise the LCD class
lcd = character_lcd.Character_LCD_RGB_I2C(i2c, lcd_columns, lcd_rows)

#clearing anything previously on lcd screen
lcd.clear()
lcd.color = [0, 0, 0]

#Defining Global Variables
    #varible to keep track of the quadrent the marker was last in
quad=0
    #Flag varible to keep track of when the quadrant is changed
change_quad=0

def writeNumber(value):
    #bus.write_byte(address, value)
    try:
        bus.write_byte_data(address, 0, value)
    except:
        print("I2C Write Error")
    return -1
    
#def writeBlock(value): #function to write block of data to arduino
#    bus.write_i2c_block_data(address, 0, value)
#    return -1

def readBlock(length = 2): #function to read block of data from arduino
    try:
        number = bus.read_i2c_block_data(address, 0, length)
    except:
        print("I2C read Error")
        number = 0
    return number

#Function that handles the detection of the aruco markers
def aruco(pic,w,l):
    current_quad=0
    ang=0
    detected=0
    #generate a grayscale image from the given input file
    pic=cv2.cvtColor(pic,cv2.COLOR_BGR2GRAY)
    
    #Create the aruco dictionary for the given tag type
    aruco_dict=cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_1000)
    
    #Create aruco paramters
    params=cv2.aruco.DetectorParameters_create()
    
    #detect function
    (corners,ids,rejected)=cv2.aruco.detectMarkers(pic,aruco_dict,parameters=params)
    
    #Loop that goes through and grabs each corner of the detected marker
    if len(corners) > 0:
        detected=1
        ids=ids.flatten()
        markers=zip(corners,ids)
        for(c,i) in markers:
            #Reshaping
            corners=c.reshape((4,2))
            (t_left,t_right,b_right,b_left)=corners
            t_left=(int(t_left[0]),int(t_left[1]))
            t_right=(int(t_right[0]),int(t_right[1]))
            b_right=(int(b_right[0]),int(b_right[1]))
            b_left=(int(b_left[0]),int(b_left[1]))
            
            
            #adding the marker id
            cv2.putText(pic,str(i),(t_left[0],t_left[1]-15),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),2)
            
            #Calculation the distance and degree offset
            fov=53.5/2
            ratio=((w-(0.5*(t_right[0]+t_left[0])))/w)
            ang=int(ratio*fov)
            cv2.putText(pic,str(ang),(t_right[0],t_right[1]-15),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),2)
            
            #Finding Quadrent
            
            #Center of Object
            cx=int((t_left[0]+b_right[0])*0.5)
            cy=int((t_left[1]+b_right[1])*0.5)
            #If to find Quadrent
            if cx < (w) and cy < (l):
                 current_quad=2
            elif cx > (w) and cy > (l):
                 current_quad=4
            elif cx < (w) and cy > (l):
                 current_quad=3
            elif cx > (w) and cy < (l):
                 current_quad=1
                
            #Update global quad and change quad flag variable
            global quad,change_quad   
            if current_quad != quad:
                quad=current_quad
                change_quad=1
            
    #Return processed picture and the quadrent that the object is in
    return(pic,quad,ang,detected)

#Start video and detection
def start():
#Define global variables
    global quad,change_quad

#Start and Calibrate Video Capture
    cap=cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FPS,24)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH,480)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT,360)
    #cap.set(cv2.CAP_PROP_AUTO_EXPOSURE,0.25)
    #cap.set(cv2.CAP_PROP_EXPOSURE,5)
    
    desiredSetpoint = "" #variable to print setpoint on lcd

    #loop to keep getting and processing frames
    while True:
        #Getting frame
        ret,frame=cap.read()
        #Running detection on the frame
        width=0.5*cap.get(3)
        length=0.5*cap.get(4)
        a = aruco(frame,width,length)
        #Show processed image
        cv2.imshow("Live Feed",a[0])
        #wating for the user to hit q and stop the stream
        if cv2.waitKey(1) == ord('q'):
            break

        
        if a[3]:
            lcd.color = [0, 0, 200]
            lcd.message = "Detected\n" + "Angle: " + str(a[2])
        else:
            lcd.color = [200, 0, 0]
            lcd.message = "Not Detected\n              "     
        
    #Release the capture and destory all the created windows
    cap.release()
    cv2.destroyAllWindows()
    lcd.clear() #clears lcd screen
    lcd.color = [0, 0, 0]

start()
